{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation with Embeddings\n",
    "\n",
    "Setup file with the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset\n",
    "\n",
    "The dataset is the book \"\" as a textfile. The orginal text from gutenberg is available at [http://www.gutenberg.org/ebooks/1661](http://www.gutenberg.org/ebooks/1661). The text contained a header that was removed in the this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/raw_text/aesop_fable.txt'\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8-sig') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Wolf A\n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GloVe Embeddings\n",
    "\n",
    "The GloVe embeddings are available at [http://nlp.stanford.edu/data/glove.6B.zip](http://nlp.stanford.edu/data/glove.6B.zip). The embeddings are in a textfile and can be loaded using the following code. The embeddings used here are the 50 dimensional embeddings and are stored in a dictionary. There are also two other dictionaries that contain the word to index and index to word mappings to make the embeddings easy to lookup by word and be able to convert tokens to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad lines: 0\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/GloVe/glove.6B.50d.txt\"\n",
    "\n",
    "embedding = {}\n",
    "idx_to_word = {}\n",
    "word_to_idx = {}\n",
    "bad_lines = 0\n",
    "\n",
    "with open(file_name, 'r', encoding='UTF-8') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        try:\n",
    "            line = line.strip()\n",
    "            match_obj = re.match(r'([^\\s]+)', line)\n",
    "            word = match_obj.group(1)\n",
    "            word_len = len(word)\n",
    "            word_vec = line[word_len:].replace('\\n', '')\n",
    "\n",
    "            embed = word_vec.strip()\n",
    "            embed = embed.split()\n",
    "            embed = np.array(embed, dtype=np.float32)\n",
    "            \n",
    "            embedding[idx] = [embed]\n",
    "            idx_to_word[idx] = word.strip()\n",
    "            word_to_idx[word.strip()] = idx\n",
    "        except:\n",
    "            bad_lines += 1\n",
    "\n",
    "print(f'Bad lines: {bad_lines}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8778121]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'waiter'\n",
    "w2 = 'waitress'\n",
    "\n",
    "w1_embed = embedding[word_to_idx[w1]]\n",
    "w2_embed = embedding[word_to_idx[w2]]\n",
    "cosine_similarity(w1_embed, w2_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Dataset\n",
    "\n",
    "The dataset for this project is the text file sliced into arrays of 20 words and the label is the next word in the array. The input data is stored initially in three lists:\n",
    "\n",
    "- `x_token`: a list of the tokenized words (as BERT tokens)\n",
    "- `x_mask`: list containing the mask for the input data\n",
    "- `y`: the next word in the array as a BERT token\n",
    "\n",
    "Even though the GloVe embedding dataset contains 400,000 words, BERT tokens are stemmed and contain unconventional words with artifacts like `#`. To ensure that an embedding can be generated for every predicted word, a out-of-vocabulary words are replaced with the word \"umm\". We'll see how this goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word):\n",
    "    if word in word_to_idx:\n",
    "        return embedding[word_to_idx[word]]\n",
    "    else:\n",
    "        return embedding[word_to_idx['umm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 22:35:20.385674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:20.418274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:20.418781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:20.420572: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-18 22:35:20.422082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:20.422599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:20.423215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:21.006451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:21.006799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:21.007107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 22:35:21.007394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9541 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 55180\n"
     ]
    }
   ],
   "source": [
    "def generate_sequences(text, seq_length):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    num_sequences = len(tokens) - seq_length\n",
    "\n",
    "    x_token = np.zeros((num_sequences, seq_length+2))\n",
    "    x_mask = np.zeros((num_sequences, seq_length+2))\n",
    "    y_token = np.zeros((num_sequences, 50), dtype=np.float32)\n",
    "\n",
    "    for i in range(0, num_sequences):\n",
    "        seq = tokens[i:i + seq_length]\n",
    "        input = tokenizer.encode_plus(seq, max_length=seq_length+2, truncation=True, padding='max_length', add_special_tokens=True, return_tensors='tf')\n",
    "\n",
    "        x_token[i, :] = input['input_ids']\n",
    "        x_mask[i, :] = input['attention_mask']\n",
    "        y_token[i, :] = get_embedding(tokens[i + seq_length])[0]\n",
    "\n",
    "    print(f'Number of sequences: {num_sequences}')\n",
    "\n",
    "    return x_token, x_mask, y_token, num_sequences\n",
    "\n",
    "seq_length = 20\n",
    "x_token, x_mask, y_token, num_sequences = generate_sequences(raw_text, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  101.  1996.  4702.  1998.  1996. 12559.  4702.  1010.  3116.  2007.\n",
      "   1037. 12559.  2004. 28473.  2013.  1996. 10671.  1010. 10395.  2025.\n",
      "   2000.   102.]\n",
      " [  101.  4702.  1998.  1996. 12559.  4702.  1010.  3116.  2007.  1037.\n",
      "  12559.  2004. 28473.  2013.  1996. 10671.  1010. 10395.  2025.  2000.\n",
      "   3913.   102.]]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "[[ 1.1417e+00  4.6283e-01  3.1850e-01 -1.0938e+00  7.7268e-01 -8.5313e-03\n",
      "  -2.7627e-01  1.9700e-01  2.5137e-01 -7.4092e-01 -5.2680e-01  6.7512e-02\n",
      "  -6.1951e-01  3.2295e-01 -2.9231e-01  2.7597e-01 -2.1011e-02 -4.3145e-01\n",
      "   8.1964e-01 -4.1744e-01 -3.3500e-01  2.3481e-01  7.0489e-01 -3.5527e-01\n",
      "  -4.2271e-01 -1.1781e+00 -4.7389e-01  3.5343e-01 -7.7644e-02 -2.8819e-01\n",
      "   2.1887e+00 -7.7166e-02 -5.3521e-01  3.7567e-01 -1.2167e-01 -1.0910e-01\n",
      "  -1.1022e-01  5.2403e-02  9.9741e-01  2.8786e-01 -6.2407e-01 -4.2667e-01\n",
      "  -1.5656e-04  6.4558e-01  4.8132e-01 -1.8291e-01 -5.5292e-01 -6.6174e-01\n",
      "  -2.7978e-01 -8.6844e-01]\n",
      " [ 3.4818e-01 -8.8657e-01 -2.6971e-01 -2.7064e-01 -4.9003e-01  4.8359e-01\n",
      "   9.5457e-01 -8.9255e-02 -6.2285e-01  1.1782e+00 -5.8385e-01 -1.2310e+00\n",
      "  -4.4248e-01  1.5747e-01  7.0326e-01 -6.0854e-01  2.2851e-02 -1.3363e-01\n",
      "  -6.0768e-01  2.8166e-01 -2.8764e-01  4.6183e-01  3.9595e-01  7.0407e-01\n",
      "  -3.4558e-01 -1.3530e+00  1.2247e-01 -2.7575e-01  1.1103e+00  8.5284e-01\n",
      "   2.8779e+00 -2.5105e-01 -2.2009e-01 -1.4588e+00 -5.2604e-01  3.6152e-01\n",
      "  -3.3094e-01 -1.6539e+00 -1.1313e+00  2.6021e-01 -1.1531e+00  6.0551e-01\n",
      "  -2.4659e-01  1.6711e-01  1.0962e+00 -4.0880e-01 -1.9643e-01 -4.8867e-01\n",
      "   2.8021e-01 -2.0419e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(x_token[:2])\n",
    "print(x_mask[:2])\n",
    "print(y_token[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert individual datasets into a single dataset\n",
    "\n",
    "In order to use the BERT layer as input for the model, the tokens and masks need to be combined into a single input and given keys that match the name of the input layers. The dataset is then shuffled, batched, and split into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((22,), (22,), (50,)), types: (tf.float64, tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_token, x_mask, y_token))\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (22,), attention_mask: (22,)}, (50,)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_input_mask(input_id, mask, y_token):\n",
    "    return {'input_ids': input_id, 'attention_mask': mask}, y_token\n",
    "\n",
    "dataset = dataset.map(combine_input_mask)\n",
    "dataset.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (32, 22), attention_mask: (32, 22)}, (32, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: <TakeDataset shapes: ({input_ids: (32, 22), attention_mask: (32, 22)}, (32, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>\n",
      "size: 1379\n",
      "tensor: <TakeDataset shapes: ({input_ids: (32, 22), attention_mask: (32, 22)}, (32, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>\n",
      "size: 172\n",
      "tensor: <TakeDataset shapes: ({input_ids: (32, 22), attention_mask: (32, 22)}, (32, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>\n",
      "size: 173\n"
     ]
    }
   ],
   "source": [
    "split = 0.8\n",
    "sample_size = int((num_sequences // batch_size) * split)\n",
    "ds_train = dataset.take(sample_size)\n",
    "dataset_validation = dataset.skip(sample_size)\n",
    "\n",
    "test_split = 0.5\n",
    "testset_size = len(list(dataset_validation))\n",
    "val_sample_size = int(testset_size * test_split)\n",
    "ds_val = dataset_validation.take(val_sample_size)\n",
    "ds_test = dataset_validation.skip(val_sample_size)\n",
    "print(f'tensor: {ds_train.take(1)}\\nsize: {len(list(ds_train))}')\n",
    "print(f'tensor: {ds_val.take(1)}\\nsize: {len(list(ds_val))}')\n",
    "print(f'tensor: {ds_test.take(1)}\\nsize: {len(list(ds_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model\n",
    "\n",
    "The model uses uncases BERT as the encoder and uses a linear layer to generate the next word. The model is trained using the Adam optimizer and the cross-entropy loss. Usually the model is categorical and uses softmax for the last Dense logit layer, but in this case we are building a regression model and want the output to most closely match the true word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 22:35:38.757220: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 22,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         787456      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           51250       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,320,946\n",
      "Trainable params: 838,706\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(seq_length+2,), name='input_ids', dtype=tf.int32)\n",
    "mask_layer = Input(shape=(seq_length+2,),\n",
    "                   name='attention_mask', dtype=tf.int32)\n",
    "\n",
    "embedding_layer = bert.bert(input_layer, attention_mask=mask_layer)[1]\n",
    "\n",
    "out = Dense(1024, activation='relu')(embedding_layer)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Dense(50)(out)\n",
    "\n",
    "model = Model(inputs=[input_layer, mask_layer], outputs=out)\n",
    "\n",
    "model.layers[2].trainable = False\n",
    "\n",
    "optimizer = SGD(learning_rate=0.00009, decay=1e-6)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.losses.mean_squared_error, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3480 - accuracy: 0.8286\n",
      "Epoch 00001: val_loss improved from inf to 0.31309, saving model to bert_model.h5\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3480 - accuracy: 0.8286 - val_loss: 0.3131 - val_accuracy: 0.8069\n",
      "Epoch 2/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8309\n",
      "Epoch 00002: val_loss did not improve from 0.31309\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3383 - accuracy: 0.8309 - val_loss: 0.3134 - val_accuracy: 0.7941\n",
      "Epoch 3/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.8318\n",
      "Epoch 00003: val_loss improved from 0.31309 to 0.30882, saving model to bert_model.h5\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3342 - accuracy: 0.8318 - val_loss: 0.3088 - val_accuracy: 0.7969\n",
      "Epoch 4/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8341\n",
      "Epoch 00004: val_loss improved from 0.30882 to 0.30819, saving model to bert_model.h5\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3278 - accuracy: 0.8341 - val_loss: 0.3082 - val_accuracy: 0.8036\n",
      "Epoch 5/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.8351\n",
      "Epoch 00005: val_loss improved from 0.30819 to 0.30704, saving model to bert_model.h5\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3242 - accuracy: 0.8351 - val_loss: 0.3070 - val_accuracy: 0.7998\n",
      "Epoch 6/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.8364\n",
      "Epoch 00006: val_loss did not improve from 0.30704\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3201 - accuracy: 0.8364 - val_loss: 0.3094 - val_accuracy: 0.7929\n",
      "Epoch 7/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8367\n",
      "Epoch 00007: val_loss improved from 0.30704 to 0.30232, saving model to bert_model.h5\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3175 - accuracy: 0.8367 - val_loss: 0.3023 - val_accuracy: 0.8011\n",
      "Epoch 8/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.8369\n",
      "Epoch 00008: val_loss did not improve from 0.30232\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3144 - accuracy: 0.8369 - val_loss: 0.3029 - val_accuracy: 0.8014\n",
      "Epoch 9/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.8375\n",
      "Epoch 00009: val_loss did not improve from 0.30232\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3112 - accuracy: 0.8375 - val_loss: 0.3028 - val_accuracy: 0.8029\n",
      "Epoch 10/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8382\n",
      "Epoch 00010: val_loss improved from 0.30232 to 0.29865, saving model to bert_model.h5\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3090 - accuracy: 0.8382 - val_loss: 0.2986 - val_accuracy: 0.8043\n",
      "Epoch 11/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.8368\n",
      "Epoch 00011: val_loss improved from 0.29865 to 0.29759, saving model to bert_model.h5\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.3072 - accuracy: 0.8368 - val_loss: 0.2976 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.8365\n",
      "Epoch 00012: val_loss did not improve from 0.29759\n",
      "1379/1379 [==============================] - 44s 32ms/step - loss: 0.3051 - accuracy: 0.8365 - val_loss: 0.2992 - val_accuracy: 0.8065\n",
      "Epoch 13/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.8367\n",
      "Epoch 00013: val_loss did not improve from 0.29759\n",
      "1379/1379 [==============================] - 45s 33ms/step - loss: 0.3033 - accuracy: 0.8367 - val_loss: 0.2995 - val_accuracy: 0.8043\n",
      "Epoch 14/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.8393\n",
      "Epoch 00014: val_loss improved from 0.29759 to 0.29453, saving model to bert_model.h5\n",
      "1379/1379 [==============================] - 46s 33ms/step - loss: 0.3000 - accuracy: 0.8393 - val_loss: 0.2945 - val_accuracy: 0.8070\n",
      "Epoch 15/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.8379\n",
      "Epoch 00015: val_loss did not improve from 0.29453\n",
      "1379/1379 [==============================] - 46s 34ms/step - loss: 0.2991 - accuracy: 0.8379 - val_loss: 0.3006 - val_accuracy: 0.7985\n",
      "Epoch 16/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.2970 - accuracy: 0.8384\n",
      "Epoch 00016: val_loss did not improve from 0.29453\n",
      "1379/1379 [==============================] - 45s 33ms/step - loss: 0.2970 - accuracy: 0.8384 - val_loss: 0.2982 - val_accuracy: 0.7991\n",
      "Epoch 17/100\n",
      "1379/1379 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.8374\n",
      "Epoch 00017: val_loss did not improve from 0.29453\n",
      "1379/1379 [==============================] - 46s 33ms/step - loss: 0.2965 - accuracy: 0.8374 - val_loss: 0.3035 - val_accuracy: 0.7922\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('bert_model.h5', monitor='val_loss',\n",
    "                     mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(ds_train, validation_data=ds_val,\n",
    "                    batch_size=64, epochs=100, shuffle=True, verbose=1, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.65%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(ds_test, verbose=0)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input(text):\n",
    "    tokens = tokenizer.encode_plus(text, max_length=seq_length+2, truncation=True, padding='max_length', add_special_tokens=True, return_tensors='tf')\n",
    "    return {\n",
    "        'input_ids': tf.cast(tokens['input_ids'], tf.float64),\n",
    "        'attention_mask': tf.cast(tokens['attention_mask'], tf.float64),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenize_input('Hello, my dog is cute but I have to give him ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.2864541e-01,  5.5811711e-02, -1.5909947e-01, -9.2552386e-02,\n",
       "        2.1683852e-01, -1.8067926e-03, -1.7929357e-01,  8.5016996e-02,\n",
       "       -6.0084559e-02, -8.4663808e-02,  3.0000153e-01,  2.5356489e-01,\n",
       "       -2.1748012e-01, -2.3434865e-01,  2.6691300e-01,  1.3098808e-01,\n",
       "        8.9706391e-02, -6.0081307e-02, -3.1706849e-01, -1.8024109e-01,\n",
       "        2.7879816e-02,  1.1860728e-01,  2.1747522e-01, -5.8191601e-02,\n",
       "        1.2222081e-03, -1.6563417e+00, -3.7204102e-01,  6.2259618e-02,\n",
       "        3.6947641e-01, -8.9596204e-02,  2.7174873e+00,  2.3923495e-01,\n",
       "       -2.7848756e-01,  2.4145372e-02,  1.9010073e-01, -1.1825155e-01,\n",
       "       -9.9026941e-02, -7.0224136e-02,  1.9530536e-01,  1.1175760e-01,\n",
       "       -8.2937535e-05,  2.2639984e-01,  9.6105769e-02, -2.2000780e-02,\n",
       "       -1.1219374e-02,  3.3097878e-02, -1.5864472e-01, -2.9289836e-01,\n",
       "       -1.8678704e-01, -1.0117057e-01], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v = KeyedVectors.load_word2vec_format(\n",
    "    'data/GloVe/glove.6B.50d_gensim.txt', binary=False, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 0.9444191455841064), ('as', 0.9376862645149231), ('but', 0.9360287189483643), ('one', 0.9291987419128418), ('to', 0.9240070581436157), ('it', 0.9221705198287964), ('well', 0.9210121035575867), ('same', 0.9172413945198059), ('only', 0.9142103791236877), ('once', 0.9112837910652161), ('the', 0.9090365171432495), ('now', 0.9071311354637146), ('when', 0.906342089176178), ('and', 0.9045966267585754), ('still', 0.9031203985214233), ('because', 0.9030216336250305), ('this', 0.9020168781280518), ('that', 0.899276614189148), ('while', 0.8976303339004517), ('rest', 0.8972018957138062)]\n"
     ]
    }
   ],
   "source": [
    "word = w2v.similar_by_vector(props[0], topn=20)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world as\n",
      "Hello, world as as\n",
      "Hello, world as as well\n",
      "Hello, world as as well one\n",
      "Hello, world as as well one well\n",
      "Hello, world as as well one well but\n",
      "Hello, world as as well one well but .\n",
      "Hello, world as as well one well but . and\n",
      "Hello, world as as well one well but . and as\n",
      "Hello, world as as well one well but . and as and\n",
      "Hello, world as as well one well but . and as and once\n",
      "Hello, world as as well one well but . and as and once .\n",
      "Hello, world as as well one well but . and as and once . as\n",
      "Hello, world as as well one well but . and as and once . as .\n",
      "Hello, world as as well one well but . and as and once . as . one\n",
      "Hello, world as as well one well but . and as and once . as . one well\n",
      "Hello, world as as well one well but . and as and once . as . one well to\n",
      "Hello, world as as well one well but . and as and once . as . one well to same\n",
      "world as as well one well but . and as and once . as . one well to same .\n",
      "as as well one well but . and as and once . as . one well to same . to\n",
      "as well one well but . and as and once . as . one well to same . to one\n",
      "well one well but . and as and once . as . one well to same . to one it\n",
      "one well but . and as and once . as . one well to same . to one it once\n",
      "well but . and as and once . as . one well to same . to one it once but\n",
      "but . and as and once . as . one well to same . to one it once but it\n",
      ". and as and once . as . one well to same . to one it once but it and\n",
      "and as and once . as . one well to same . to one it once but it and well\n",
      "as and once . as . one well to same . to one it once but it and well as\n",
      "and once . as . one well to same . to one it once but it and well as but\n",
      "once . as . one well to same . to one it once but it and well as but once\n"
     ]
    }
   ],
   "source": [
    "start_text = 'Hello, world'\n",
    "generated_text = start_text\n",
    "from random import randint, seed\n",
    "seed(42)\n",
    "\n",
    "for i in range(0, 30):\n",
    "    text = tokenize_input(generated_text)\n",
    "    props = model.predict(text)\n",
    "    top_word = w2v.similar_by_vector(props[0], topn=10)[randint(0, 9)][0]\n",
    "    generated_text = \" \".join(f'{generated_text} {top_word}'.split(' ')[-20:])\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation with Embeddings\n",
    "\n",
    "Setup file with the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset\n",
    "\n",
    "The dataset is the book \"\" as a textfile. The orginal text from gutenberg is available at [http://www.gutenberg.org/ebooks/1661](http://www.gutenberg.org/ebooks/1661). The text contained a header that was removed in the this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/raw_text/aesop_fable.txt'\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8-sig') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Wolf A\n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GloVe Embeddings\n",
    "\n",
    "The GloVe embeddings are available at [http://nlp.stanford.edu/data/glove.6B.zip](http://nlp.stanford.edu/data/glove.6B.zip). The embeddings are in a textfile and can be loaded using the following code. The embeddings used here are the 50 dimensional embeddings and are stored in a dictionary. There are also two other dictionaries that contain the word to index and index to word mappings to make the embeddings easy to lookup by word and be able to convert tokens to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad lines: 0\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/GloVe/glove.6B.50d.txt\"\n",
    "\n",
    "embedding = {}\n",
    "idx_to_word = {}\n",
    "word_to_idx = {}\n",
    "bad_lines = 0\n",
    "\n",
    "with open(file_name, 'r', encoding='UTF-8') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        try:\n",
    "            line = line.strip()\n",
    "            match_obj = re.match(r'([^\\s]+)', line)\n",
    "            word = match_obj.group(1)\n",
    "            word_len = len(word)\n",
    "            word_vec = line[word_len:].replace('\\n', '')\n",
    "\n",
    "            embed = word_vec.strip()\n",
    "            embed = embed.split()\n",
    "            embed = np.array(embed, dtype=np.float32)\n",
    "            \n",
    "            embedding[idx] = [embed]\n",
    "            idx_to_word[idx] = word.strip()\n",
    "            word_to_idx[word.strip()] = idx\n",
    "        except:\n",
    "            bad_lines += 1\n",
    "\n",
    "print(f'Bad lines: {bad_lines}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8778121]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'waiter'\n",
    "w2 = 'waitress'\n",
    "\n",
    "w1_embed = embedding[word_to_idx[w1]]\n",
    "w2_embed = embedding[word_to_idx[w2]]\n",
    "cosine_similarity(w1_embed, w2_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Dataset\n",
    "\n",
    "The dataset for this project is the text file sliced into arrays of 20 words and the label is the next word in the array. The input data is stored initially in three lists:\n",
    "\n",
    "- `x`: a list of 20 words\n",
    "- `x_token`: a list of the tokenized words (as BERT tokens)\n",
    "- `x_mask`: list containing the mask for the input data\n",
    "- `y`: the next word in the array as a BERT token\n",
    "\n",
    "Even though the GloVe embedding dataset contains 400,000 words, BERT tokens are stemmed and contain unconventional words with artifacts like `#`. To ensure that an embedding can be generated for every predicted word, a out-of-vocabulary words are replaced with the word \"umm\". We'll see how this goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word):\n",
    "    if word in word_to_idx:\n",
    "        return embedding[word_to_idx[word]]\n",
    "    else:\n",
    "        return embedding[word_to_idx['umm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 16:04:15.302823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.332987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.333510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.335444: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-18 16:04:15.336784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.337100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.337390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.884908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.885318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.885614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 16:04:15.885885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9164 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 55180\n"
     ]
    }
   ],
   "source": [
    "def generate_sequences(text, seq_length):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    num_sequences = len(tokens) - seq_length\n",
    "    \n",
    "    x = []\n",
    "    x_token = np.zeros((num_sequences, seq_length+2))\n",
    "    x_mask = np.zeros((num_sequences, seq_length+2))\n",
    "    y_token = np.zeros((num_sequences, 50), dtype=np.float32)\n",
    "\n",
    "    for i in range(0, num_sequences):\n",
    "        seq = tokens[i:i + seq_length]\n",
    "        input = tokenizer.encode_plus(seq, max_length=seq_length+2, truncation=True, padding='max_length', add_special_tokens=True, return_tensors='tf')\n",
    "        \n",
    "        x.append(seq)\n",
    "        x_token[i, :] = input['input_ids']\n",
    "        x_mask[i, :] = input['attention_mask']\n",
    "        y_token[i, :] = get_embedding(tokens[i + seq_length])[0]\n",
    "\n",
    "    print(f'Number of sequences: {num_sequences}')\n",
    "\n",
    "    return x, x_token, x_mask, y_token, num_sequences\n",
    "\n",
    "seq_length = 20\n",
    "x, x_token, x_mask, y_token, num_sequences = generate_sequences(raw_text, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'wolf', 'and', 'the', 'lamb', 'wolf', ',', 'meeting', 'with', 'a', 'lamb', 'as', '##tray', 'from', 'the', 'fold', ',', 'resolved', 'not', 'to'], ['wolf', 'and', 'the', 'lamb', 'wolf', ',', 'meeting', 'with', 'a', 'lamb', 'as', '##tray', 'from', 'the', 'fold', ',', 'resolved', 'not', 'to', 'lay']]\n",
      "[[  101.  1996.  4702.  1998.  1996. 12559.  4702.  1010.  3116.  2007.\n",
      "   1037. 12559.  2004. 28473.  2013.  1996. 10671.  1010. 10395.  2025.\n",
      "   2000.   102.]\n",
      " [  101.  4702.  1998.  1996. 12559.  4702.  1010.  3116.  2007.  1037.\n",
      "  12559.  2004. 28473.  2013.  1996. 10671.  1010. 10395.  2025.  2000.\n",
      "   3913.   102.]]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "[[ 1.1417e+00  4.6283e-01  3.1850e-01 -1.0938e+00  7.7268e-01 -8.5313e-03\n",
      "  -2.7627e-01  1.9700e-01  2.5137e-01 -7.4092e-01 -5.2680e-01  6.7512e-02\n",
      "  -6.1951e-01  3.2295e-01 -2.9231e-01  2.7597e-01 -2.1011e-02 -4.3145e-01\n",
      "   8.1964e-01 -4.1744e-01 -3.3500e-01  2.3481e-01  7.0489e-01 -3.5527e-01\n",
      "  -4.2271e-01 -1.1781e+00 -4.7389e-01  3.5343e-01 -7.7644e-02 -2.8819e-01\n",
      "   2.1887e+00 -7.7166e-02 -5.3521e-01  3.7567e-01 -1.2167e-01 -1.0910e-01\n",
      "  -1.1022e-01  5.2403e-02  9.9741e-01  2.8786e-01 -6.2407e-01 -4.2667e-01\n",
      "  -1.5656e-04  6.4558e-01  4.8132e-01 -1.8291e-01 -5.5292e-01 -6.6174e-01\n",
      "  -2.7978e-01 -8.6844e-01]\n",
      " [ 3.4818e-01 -8.8657e-01 -2.6971e-01 -2.7064e-01 -4.9003e-01  4.8359e-01\n",
      "   9.5457e-01 -8.9255e-02 -6.2285e-01  1.1782e+00 -5.8385e-01 -1.2310e+00\n",
      "  -4.4248e-01  1.5747e-01  7.0326e-01 -6.0854e-01  2.2851e-02 -1.3363e-01\n",
      "  -6.0768e-01  2.8166e-01 -2.8764e-01  4.6183e-01  3.9595e-01  7.0407e-01\n",
      "  -3.4558e-01 -1.3530e+00  1.2247e-01 -2.7575e-01  1.1103e+00  8.5284e-01\n",
      "   2.8779e+00 -2.5105e-01 -2.2009e-01 -1.4588e+00 -5.2604e-01  3.6152e-01\n",
      "  -3.3094e-01 -1.6539e+00 -1.1313e+00  2.6021e-01 -1.1531e+00  6.0551e-01\n",
      "  -2.4659e-01  1.6711e-01  1.0962e+00 -4.0880e-01 -1.9643e-01 -4.8867e-01\n",
      "   2.8021e-01 -2.0419e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(x[:2])\n",
    "print(x_token[:2])\n",
    "print(x_mask[:2])\n",
    "print(y_token[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert individual datasets into a single dataset\n",
    "\n",
    "In order to use the BERT layer as input for the model, the tokens and masks need to be combined into a single input and given keys that match the name of the input layers. The dataset is then shuffled, batched, and split into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((22,), (22,), (50,)), types: (tf.float64, tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_token, x_mask, y_token))\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (22,), attention_mask: (22,)}, (50,)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_input_mask(input_id, mask, y_token):\n",
    "    return {'input_ids': input_id, 'attention_mask': mask}, y_token\n",
    "\n",
    "dataset = dataset.map(combine_input_mask)\n",
    "dataset.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (32, 22), attention_mask: (32, 22)}, (32, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: <TakeDataset shapes: ({input_ids: (32, 22), attention_mask: (32, 22)}, (32, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>\n",
      "size: 1379\n",
      "tensor: <TakeDataset shapes: ({input_ids: (32, 22), attention_mask: (32, 22)}, (32, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>\n",
      "size: 172\n",
      "tensor: <TakeDataset shapes: ({input_ids: (32, 22), attention_mask: (32, 22)}, (32, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float32)>\n",
      "size: 173\n"
     ]
    }
   ],
   "source": [
    "split = 0.8\n",
    "sample_size = int((num_sequences // batch_size) * split)\n",
    "ds_train = dataset.take(sample_size)\n",
    "dataset_validation = dataset.skip(sample_size)\n",
    "\n",
    "test_split = 0.5\n",
    "testset_size = len(list(dataset_validation))\n",
    "val_sample_size = int(testset_size * test_split)\n",
    "ds_val = dataset_validation.take(val_sample_size)\n",
    "ds_test = dataset_validation.skip(val_sample_size)\n",
    "print(f'tensor: {ds_train.take(1)}\\nsize: {len(list(ds_train))}')\n",
    "print(f'tensor: {ds_val.take(1)}\\nsize: {len(list(ds_val))}')\n",
    "print(f'tensor: {ds_test.take(1)}\\nsize: {len(list(ds_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model\n",
    "\n",
    "The model uses uncases BERT as the encoder and uses a linear layer to generate the next word. The model is trained using the Adam optimizer and the cross-entropy loss. Usually the model is categorical and uses softmax for the last Dense logit layer, but in this case we are building a regression model and want the output to most closely match the true word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 16:21:56.263304: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 22,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         787456      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           51250       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,320,946\n",
      "Trainable params: 838,706\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(seq_length+2,), name='input_ids', dtype=tf.int32)\n",
    "mask_layer = Input(shape=(seq_length+2,),\n",
    "                   name='attention_mask', dtype=tf.int32)\n",
    "\n",
    "embedding_layer = bert.bert(input_layer, attention_mask=mask_layer)[1]\n",
    "\n",
    "out = Dense(1024, activation='relu')(embedding_layer)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Dense(50)(out)\n",
    "\n",
    "model = Model(inputs=[input_layer, mask_layer], outputs=out)\n",
    "\n",
    "model.layers[2].trainable = False\n",
    "\n",
    "optimizer = SGD(learning_rate=0.00009, decay=1e-6)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.losses.mean_squared_error, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1379/1379 [==============================] - 58s 39ms/step - loss: 0.4908 - accuracy: 0.6605 - val_loss: 0.3448 - val_accuracy: 0.7889\n",
      "Epoch 2/100\n",
      "1379/1379 [==============================] - 49s 36ms/step - loss: 0.3618 - accuracy: 0.8228 - val_loss: 0.3208 - val_accuracy: 0.7943\n",
      "Epoch 3/100\n",
      "1379/1379 [==============================] - 54s 39ms/step - loss: 0.3461 - accuracy: 0.8274 - val_loss: 0.3172 - val_accuracy: 0.7998\n",
      "Epoch 4/100\n",
      "1379/1379 [==============================] - 55s 40ms/step - loss: 0.3374 - accuracy: 0.8328 - val_loss: 0.3086 - val_accuracy: 0.8049\n",
      "Epoch 5/100\n",
      "1379/1379 [==============================] - 49s 35ms/step - loss: 0.3317 - accuracy: 0.8346 - val_loss: 0.3107 - val_accuracy: 0.8009\n",
      "Epoch 6/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.3261 - accuracy: 0.8373 - val_loss: 0.3094 - val_accuracy: 0.7958\n",
      "Epoch 7/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.3228 - accuracy: 0.8374 - val_loss: 0.3100 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.3185 - accuracy: 0.8387 - val_loss: 0.3086 - val_accuracy: 0.8049\n",
      "Epoch 9/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.3158 - accuracy: 0.8382 - val_loss: 0.3075 - val_accuracy: 0.7998\n",
      "Epoch 10/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.3123 - accuracy: 0.8378 - val_loss: 0.3003 - val_accuracy: 0.8060\n",
      "Epoch 11/100\n",
      "1379/1379 [==============================] - 48s 34ms/step - loss: 0.3102 - accuracy: 0.8378 - val_loss: 0.3011 - val_accuracy: 0.8063\n",
      "Epoch 12/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.3076 - accuracy: 0.8388 - val_loss: 0.3019 - val_accuracy: 0.8023\n",
      "Epoch 13/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.3051 - accuracy: 0.8390 - val_loss: 0.2966 - val_accuracy: 0.8070\n",
      "Epoch 14/100\n",
      "1379/1379 [==============================] - 53s 38ms/step - loss: 0.3029 - accuracy: 0.8378 - val_loss: 0.3025 - val_accuracy: 0.7925\n",
      "Epoch 15/100\n",
      "1379/1379 [==============================] - 53s 38ms/step - loss: 0.3009 - accuracy: 0.8376 - val_loss: 0.2950 - val_accuracy: 0.8110\n",
      "Epoch 16/100\n",
      "1379/1379 [==============================] - 49s 35ms/step - loss: 0.2987 - accuracy: 0.8395 - val_loss: 0.2982 - val_accuracy: 0.8056\n",
      "Epoch 17/100\n",
      "1379/1379 [==============================] - 48s 34ms/step - loss: 0.2978 - accuracy: 0.8372 - val_loss: 0.2977 - val_accuracy: 0.8032\n",
      "Epoch 18/100\n",
      "1379/1379 [==============================] - 49s 36ms/step - loss: 0.2960 - accuracy: 0.8383 - val_loss: 0.2987 - val_accuracy: 0.8049\n",
      "Epoch 19/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.2947 - accuracy: 0.8379 - val_loss: 0.2942 - val_accuracy: 0.8085\n",
      "Epoch 20/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.2935 - accuracy: 0.8379 - val_loss: 0.2982 - val_accuracy: 0.7996\n",
      "Epoch 21/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.2911 - accuracy: 0.8394 - val_loss: 0.2966 - val_accuracy: 0.8025\n",
      "Epoch 22/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.2909 - accuracy: 0.8381 - val_loss: 0.2975 - val_accuracy: 0.8034\n",
      "Epoch 23/100\n",
      "1379/1379 [==============================] - 49s 35ms/step - loss: 0.2896 - accuracy: 0.8381 - val_loss: 0.2958 - val_accuracy: 0.8038\n",
      "Epoch 24/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.2884 - accuracy: 0.8377 - val_loss: 0.2930 - val_accuracy: 0.8105\n",
      "Epoch 25/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.2871 - accuracy: 0.8390 - val_loss: 0.2939 - val_accuracy: 0.8087\n",
      "Epoch 26/100\n",
      "1379/1379 [==============================] - 49s 36ms/step - loss: 0.2861 - accuracy: 0.8383 - val_loss: 0.2990 - val_accuracy: 0.8005\n",
      "Epoch 27/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.2853 - accuracy: 0.8379 - val_loss: 0.2967 - val_accuracy: 0.8011\n",
      "Epoch 28/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.2842 - accuracy: 0.8388 - val_loss: 0.2921 - val_accuracy: 0.8080\n",
      "Epoch 29/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.2833 - accuracy: 0.8389 - val_loss: 0.2919 - val_accuracy: 0.8092\n",
      "Epoch 30/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.2821 - accuracy: 0.8383 - val_loss: 0.2954 - val_accuracy: 0.7980\n",
      "Epoch 31/100\n",
      "1379/1379 [==============================] - 47s 34ms/step - loss: 0.2821 - accuracy: 0.8378 - val_loss: 0.2947 - val_accuracy: 0.8031\n",
      "Epoch 32/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.2818 - accuracy: 0.8377 - val_loss: 0.2914 - val_accuracy: 0.8096\n",
      "Epoch 33/100\n",
      "1379/1379 [==============================] - 49s 35ms/step - loss: 0.2801 - accuracy: 0.8389 - val_loss: 0.2922 - val_accuracy: 0.8052\n",
      "Epoch 34/100\n",
      "1379/1379 [==============================] - 50s 36ms/step - loss: 0.2795 - accuracy: 0.8386 - val_loss: 0.2956 - val_accuracy: 0.8007\n",
      "Epoch 35/100\n",
      "1379/1379 [==============================] - 49s 36ms/step - loss: 0.2792 - accuracy: 0.8384 - val_loss: 0.2938 - val_accuracy: 0.8076\n",
      "Epoch 36/100\n",
      "1379/1379 [==============================] - 48s 35ms/step - loss: 0.2788 - accuracy: 0.8383 - val_loss: 0.2940 - val_accuracy: 0.8052\n",
      "Epoch 37/100\n",
      "1379/1379 [==============================] - 49s 35ms/step - loss: 0.2778 - accuracy: 0.8386 - val_loss: 0.2956 - val_accuracy: 0.8003\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "history = model.fit(ds_train, validation_data=ds_val,\n",
    "                    batch_size=64, epochs=100, shuffle=True, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.51%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(ds_test, verbose=0)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
